# AI-Powered Resume Parser Pipeline 

## Overview

D·ª± √°n n√†y x√¢y d·ª±ng m·ªôt **h·ªá th·ªëng tr√≠ch xu·∫•t th√¥ng tin t·ª± ƒë·ªông t·ª´ CV (Resumes)** d·ª±a tr√™n k·ªπ thu·∫≠t **Named Entity Recognition (NER)**. H·ªá th·ªëng cho ph√©p chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu **phi c·∫•u tr√∫c (PDF)** sang **JSON c√≥ c·∫•u tr√∫c**, ph·ª•c v·ª• cho:

* C√°c b√†i to√°n **Data Science / Machine Learning**
* X√¢y d·ª±ng **Data Lake / Data Warehouse**
* T√≠ch h·ª£p v√†o h·ªá th·ªëng **ATS (Applicant Tracking System)**

---

## System Architecture & Pipeline

H·ªá th·ªëng ƒë∆∞·ª£c thi·∫øt k·∫ø theo m√¥ h√¨nh **Modular Pipeline**, ƒë·∫£m b·∫£o **t√≠nh linh ho·∫°t**, **kh·∫£ nƒÉng m·ªü r·ªông** v√† **d·ªÖ b·∫£o tr√¨**.

![System Architecture](docs/img/system_architecture.png)

### Pipeline Flow

| Stage | Module               | Description                                                          |
| ----- | -------------------- | -------------------------------------------------------------------- |
| 1     | **Data Ingestion**   | Ti·∫øp nh·∫≠n file PDF th√¥ t·ª´ th∆∞ m·ª•c `data/raw/`                        |
| 2     | **OCR Layer**        | S·ª≠ d·ª•ng **Apache Tika Engine** ƒë·ªÉ tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ PDF ph·ª©c t·∫°p |
| 3     | **NLP Engine**       | **SpaCy Custom NER Model** b√≥c t√°ch c√°c th·ª±c th·ªÉ quan tr·ªçng          |
| 4     | **Data Persistence** | Chu·∫©n h√≥a & l∆∞u k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng JSON t·∫°i `data/processed/`         |

---

## Project Structure

```
resume-parser/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # CV PDF ƒë·∫ßu v√†o
‚îÇ   ‚îú‚îÄ‚îÄ processed/          # Output JSON
‚îÇ   ‚îî‚îÄ‚îÄ annotations/        # D·ªØ li·ªáu g√°n nh√£n NER
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ ocr/                # Apache Tika wrapper
‚îÇ   ‚îú‚îÄ‚îÄ nlp/                # SpaCy NER pipeline
‚îÇ   ‚îî‚îÄ‚îÄ utils/              # Helper functions
‚îú‚îÄ‚îÄ models/                 # NER trained models
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ images/             # Diagram & illustrations
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## Model Evaluation

Sau qu√° tr√¨nh **Data Cleaning**, x·ª≠ l√Ω l·ªói g√°n nh√£n th·ª±c th·ªÉ (**SpaCy E024**) v√† hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh, k·∫øt qu·∫£ **Baseline Evaluation** ƒë·∫°t ƒë∆∞·ª£c nh∆∞ sau:

###  NER Performance Metrics

| Entity Label           | Precision | Recall   | F1-Score |
| ---------------------- | --------- | -------- | -------- |
| Name                   | 0.85      | 0.78     | 0.81     |
| Skills                 | 0.72      | 0.65     | 0.68     |
| College Name           | 0.88      | 0.82     | 0.85     |
| Degree                 | 0.80      | 0.75     | 0.77     |
| **Overall (Weighted)** | **0.55**  | **0.48** | **0.51** |

> **Note**
>
> * ƒê√°nh gi√° tr√™n **174 CV samples**
> * M√¥ h√¨nh ho·∫°t ƒë·ªông t·ªët v·ªõi c√°c tr∆∞·ªùng th√¥ng tin c·ªë ƒë·ªãnh
> * Hi·ªáu nƒÉng gi·∫£m khi CV c√≥ **layout chia c·ªôt (2-column layout)**

---

##  Tech Stack

| Layer                | Technology                   |
| -------------------- | ---------------------------- |
| Programming Language | **Python 3.10**              |
| NLP Framework        | **SpaCy v3.7 (Custom NER)**  |
| OCR Engine           | **Apache Tika (Java-based)** |
| Containerization     | **Docker**                   |
| Cloud Ready          | **AWS S3, Lambda, Textract** |

---

## Installation & Usage

### 1Ô∏èPrerequisites

* Docker Desktop (Windows / macOS / Linux)
* RAM ‚â• 8GB (khuy·∫øn ngh·ªã khi train NER)

---

###  Build Docker Image

```bash
docker build -t resume-parser-app .
```

---

###  Run Container (Mount Data)

Mount th∆∞ m·ª•c d·ªØ li·ªáu t·ª´ m√°y v·∫≠t l√Ω v√†o container:

```bash
docker run --name my-parser \
  -v "D:/Resume Parser_NLP/data:/app/data" \
  resume-parser-app
```

üìå **Output** s·∫Ω ƒë∆∞·ª£c sinh t·ª± ƒë·ªông t·∫°i:

```
data/processed/*.json
```

---

##  Output Sample (JSON)

```json
{
  "name": "Nguyen Van A",
  "skills": ["Python", "SQL", "Machine Learning"],
  "degree": "Bachelor of Computer Science",
  "college": "Ho Chi Minh University of Technology"
}
```

---

##  Future Roadmap

###  Planned Improvements

* **Advanced OCR**:
  T√≠ch h·ª£p **AWS Textract** ƒë·ªÉ x·ª≠ l√Ω ho√†n h·∫£o CV d·∫°ng **2-column / complex layout**

* **Transformer-based NER**:
  Th·ª≠ nghi·ªám **BERT / RoBERTa / LayoutLM** ƒë·ªÉ n√¢ng cao hi·ªÉu bi·∫øt ng·ªØ c·∫£nh

* **Cloud Deployment**:
  Tri·ªÉn khai **Serverless Pipeline tr√™n AWS** cho x·ª≠ l√Ω CV th·ªùi gian th·ª±c

* **ATS Integration**:
  Cung c·∫•p REST API ƒë·ªÉ t√≠ch h·ª£p tr·ª±c ti·∫øp v√†o h·ªá th·ªëng tuy·ªÉn d·ª•ng

---

