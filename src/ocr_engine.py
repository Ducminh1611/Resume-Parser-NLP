import os
import re
import json
import spacy
from tika import parser

class ResumeParserPipeline:
    def __init__(self, model_path):
        """Khá»Ÿi táº¡o Pipeline vÃ  náº¡p 'bá»™ nÃ£o' AI vÃ o bá»™ nhá»›."""
        print(f"ğŸ§  Äang khá»Ÿi Ä‘á»™ng AI tá»«: {model_path}...")
        try:
            self.nlp = spacy.load(model_path)
            print("âœ… AI Ä‘Ã£ sáºµn sÃ ng!")
        except Exception as e:
            print(f"âŒ Lá»—i khi táº£i mÃ´ hÃ¬nh: {e}")
            self.nlp = None

    def _extract_text(self, pdf_path):
        """Sá»­ dá»¥ng Apache Tika Ä‘á»ƒ Ä‘á»c PDF thÃ nh Text."""
        try:
            parsed_pdf = parser.from_file(pdf_path)
            text = parsed_pdf.get('content', '')
            if not text:
                return ""
            
            # LÃ m sáº¡ch text cÆ¡ báº£n
            text = re.sub(r'\n+', '\n', text)
            text = re.sub(r'\s+', ' ', text).strip()
            return text
        except Exception as e:
            print(f"âŒ Lá»—i khi Ä‘á»c PDF {pdf_path}: {e}")
            return ""

    def process_resume(self, pdf_path):
        """HÃ m chÃ­nh: Xá»­ lÃ½ End-to-End má»™t file CV."""
        print(f"\nğŸ“„ Äang xá»­ lÃ½: {os.path.basename(pdf_path)}")
        
        # 1. TrÃ­ch xuáº¥t Text
        raw_text = self._extract_text(pdf_path)
        if not raw_text:
            return {"status": "error", "message": "KhÃ´ng thá»ƒ trÃ­ch xuáº¥t text."}

        # 2. ÄÆ°a Text cho AI bÃ³c tÃ¡ch
        if not self.nlp:
            return {"status": "error", "message": "MÃ´ hÃ¬nh AI chÆ°a Ä‘Æ°á»£c táº£i."}
            
        doc = self.nlp(raw_text)
        
        # 3. ÄÃ³ng gÃ³i káº¿t quáº£ thÃ nh JSON cÃ³ cáº¥u trÃºc
        entities_extracted = []
        for ent in doc.ents:
            entities_extracted.append({
                "label": ent.label_,
                "value": ent.text
            })

        result = {
            "status": "success",
            "file_name": os.path.basename(pdf_path),
            "text_length": len(raw_text),
            "entities": entities_extracted
        }
        
        return result

if __name__ == "__main__":
    # Äáº£m báº£o báº¡n Ä‘ang cháº¡y file nÃ y tá»« thÆ° má»¥c gá»‘c cá»§a dá»± Ã¡n (Resume_Parser_Project)
    MODEL_DIR = "models/model-best"
    
    # Khá»Ÿi táº¡o há»‡ thá»‘ng
    parser_system = ResumeParserPipeline(model_path=MODEL_DIR)
    
    # Äá»c thá»­ má»™t file PDF cÃ³ trong thÆ° má»¥c data/raw/
    # (Báº¡n hÃ£y cháº¯c cháº¯n trong folder data/raw/ cÃ³ 1 file PDF tÃªn lÃ  sample_cv.pdf nhÃ©)
    TEST_PDF = "data/raw/sample_cv.pdf"
    
    if os.path.exists(TEST_PDF):
        final_result = parser_system.process_resume(TEST_PDF)
        
        print("\nğŸ“Š Káº¾T QUáº¢ Äáº¦U RA (JSON FORMAT DÃ€NH CHO DATA LAKE):")
        # In ra Ä‘á»‹nh dáº¡ng JSON Ä‘áº¹p máº¯t
        print(json.dumps(final_result, indent=4, ensure_ascii=False))
        
        # LÆ°u káº¿t quáº£ ra file JSON vÃ o thÆ° má»¥c processed
        os.makedirs("data/processed", exist_ok=True)
        output_file = f"data/processed/{os.path.basename(TEST_PDF)}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_result, f, indent=4, ensure_ascii=False)
        print(f"\nğŸ’¾ ÄÃ£ lÆ°u káº¿t quáº£ táº¡i: {output_file}")
    else:
        print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y file {TEST_PDF} Ä‘á»ƒ test. HÃ£y copy 1 file PDF vÃ o Ä‘Ã³ nhÃ©!")